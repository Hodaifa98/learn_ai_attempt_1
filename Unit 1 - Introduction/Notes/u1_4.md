# Model Evaluation, Performance Improvement, and Limitations of Machine Learning

## Model Performance Evaluation

After training a machine learning model, it's crucial to evaluate how well it performs using appropriate metrics.

### Common Evaluation Metrics

- **Accuracy**: Percentage of correct predictions (useful when classes are balanced)
- **Precision**: How many predicted positives are actually positive
- **Recall (Sensitivity)**: How many actual positives were correctly predicted
- **F1 Score**: Harmonic mean of precision and recall (useful for imbalanced datasets)
- **Mean Squared Error (MSE)**: Average squared difference between predicted and actual values (used in regression)
- **Confusion Matrix**: A table showing true vs. predicted labels for classification tasks

---

## Improving Model Performance

- **Feature Engineering**: Creating better input variables from existing data
- **Hyperparameter Tuning**: Adjusting parameters like learning rate, depth of trees, etc.
- **Cross-Validation**: Splitting data into multiple parts to ensure the model generalizes well
- **Ensemble Methods**: Combining multiple models (e.g., Random Forest, Gradient Boosting)
- **Data Augmentation**: Expanding the dataset by generating new, synthetic examples (especially in image tasks)
- **Regularization**: Techniques to reduce overfitting (e.g., L1, L2 penalties)

---

## Limitations of Machine Learning

### Overfitting
The model learns the training data too well, including noise and outliers, and performs poorly on new, unseen data.

**Symptoms:**
- High training accuracy
- Low test accuracy

**Solutions:**
- Use simpler models
- Add regularization
- Use more training data
- Apply cross-validation

### Underfitting
The model is too simple to capture the underlying structure of the data.

**Symptoms:**
- Low training and test accuracy

**Solutions:**
- Use a more complex model
- Add more relevant features
- Reduce regularization

---

## Other Common Limitations

- **Bias in Data**: If training data is biased, predictions will be biased
- **Data Dependency**: ML models require a large amount of quality data
- **Interpretability**: Complex models (e.g., deep learning) can be hard to interpret
- **Computational Cost**: Training can be resource-intensive

---

## Summary

Machine learning is a powerful tool but requires careful attention to data, model selection, evaluation, and tuning. Understanding its limitations helps in applying it responsibly and effectively.
